python expt_self_supervised_training.py 
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Training:  airplane ; Model ID: 3db61220251b3c9de719b5362fe06bbb
--------------------
Running self_supervised_training:  2022-02-18 08:00:59.936222
--------------------
device is  cuda
--------------------
Number of trainable parameters:  900778
EPOCH : 1 TIME:  2022-02-18 08:01:02.982269
Training on real data with self-supervision: 
Batch  1  loss:  2.7849252223968506  pc loss:  0.11036451160907745  kp loss:  0.02581234835088253
Batch  1  fra cert:  0.6399999856948853
Batch  2  loss:  2.489469051361084  pc loss:  0.09818296134471893  kp loss:  0.034895021468400955
Batch  2  fra cert:  0.7999999523162842
Batch  3  loss:  2.5888173580169678  pc loss:  0.10239296406507492  kp loss:  0.02899325080215931
Batch  3  fra cert:  0.7599999904632568
Batch  4  loss:  2.7982280254364014  pc loss:  0.11082196980714798  kp loss:  0.02767864614725113
Batch  4  fra cert:  0.699999988079071
Batch  5  loss:  2.049457550048828  pc loss:  0.0807763934135437  kp loss:  0.030047547072172165
Batch  5  fra cert:  0.85999995470047
Batch  6  loss:  2.072129487991333  pc loss:  0.08183459937572479  kp loss:  0.02626444213092327
Batch  6  fra cert:  0.85999995470047
Batch  7  loss:  1.8910800218582153  pc loss:  0.0745682641863823  kp loss:  0.02687341719865799
Batch  7  fra cert:  0.8799999952316284
Batch  8  loss:  1.9874444007873535  pc loss:  0.07853979617357254  kp loss:  0.023949546739459038
Batch  8  fra cert:  0.85999995470047
Batch  9  loss:  2.1669490337371826  pc loss:  0.08590488880872726  kp loss:  0.019326813519001007
Batch  9  fra cert:  0.7799999713897705
Batch  10  loss:  1.930018663406372  pc loss:  0.07647238671779633  kp loss:  0.01820903830230236
Batch  10  fra cert:  0.8399999737739563
Validation on real data: 
LOSS self-supervised train 2.275851881504059, valid (%cert) 0.8399999737739563
EPOCH : 2 TIME:  2022-02-18 08:35:35.356890
Training on real data with self-supervision: 
Batch  1  loss:  1.8243253231048584  pc loss:  0.07226349413394928  kp loss:  0.017738016322255135
Batch  1  fra cert:  0.9399999976158142
Batch  2  loss:  2.1893680095672607  pc loss:  0.08699318766593933  kp loss:  0.014538256451487541
Batch  2  fra cert:  0.7599999904632568
Batch  3  loss:  1.8912243843078613  pc loss:  0.07502423971891403  kp loss:  0.015618483535945415
Batch  3  fra cert:  0.8799999952316284
Batch  4  loss:  2.4029393196105957  pc loss:  0.09546922147274017  kp loss:  0.01620897650718689
Batch  4  fra cert:  0.8399999737739563
Batch  5  loss:  2.0762829780578613  pc loss:  0.08238215744495392  kp loss:  0.01672905869781971
Batch  5  fra cert:  0.8399999737739563
Batch  6  loss:  2.072335958480835  pc loss:  0.0821247398853302  kp loss:  0.01921759359538555
Batch  6  fra cert:  0.8199999928474426
Batch  7  loss:  1.5169620513916016  pc loss:  0.060017623007297516  kp loss:  0.016521474346518517
Batch  7  fra cert:  0.85999995470047
Batch  8  loss:  1.7526745796203613  pc loss:  0.06936686486005783  kp loss:  0.018502971157431602
Batch  8  fra cert:  0.8199999928474426
Batch  9  loss:  1.4669009447097778  pc loss:  0.057956695556640625  kp loss:  0.017983561381697655
Batch  9  fra cert:  0.8999999761581421
Batch  10  loss:  1.8223991394042969  pc loss:  0.07235763221979141  kp loss:  0.013458318077027798
Batch  10  fra cert:  0.7999999523162842
Validation on real data: 
LOSS self-supervised train 1.901541268825531, valid (%cert) 0.8199999928474426
EPOCH : 3 TIME:  2022-02-18 09:03:59.050408
Training on real data with self-supervision: 
Batch  1  loss:  1.6077357530593872  pc loss:  0.06377886980772018  kp loss:  0.013264060020446777
Batch  1  fra cert:  0.8799999952316284
Batch  2  loss:  1.0696523189544678  pc loss:  0.042261168360710144  kp loss:  0.01312320213764906
Batch  2  fra cert:  0.9399999976158142
Batch  3  loss:  1.450890302658081  pc loss:  0.05763842910528183  kp loss:  0.009929499588906765
Batch  3  fra cert:  0.8799999952316284
Batch  4  loss:  1.5132203102111816  pc loss:  0.06007448211312294  kp loss:  0.011358232237398624
Batch  4  fra cert:  0.8199999928474426
Batch  5  loss:  1.6579266786575317  pc loss:  0.06582941859960556  kp loss:  0.012191219255328178
Batch  5  fra cert:  0.8999999761581421
Batch  6  loss:  1.453877568244934  pc loss:  0.05765946954488754  kp loss:  0.01239084918051958
Batch  6  fra cert:  0.9199999570846558
Batch  7  loss:  1.1669046878814697  pc loss:  0.04609793797135353  kp loss:  0.014456289820373058
Batch  7  fra cert:  0.9599999785423279
Batch  8  loss:  1.5115543603897095  pc loss:  0.059979625046253204  kp loss:  0.012063704431056976
Batch  8  fra cert:  0.8399999737739563
Batch  9  loss:  1.3834096193313599  pc loss:  0.05479546636343002  kp loss:  0.013522959314286709
Batch  9  fra cert:  0.9199999570846558
Batch  10  loss:  1.4578430652618408  pc loss:  0.057875052094459534  kp loss:  0.010966808535158634
Batch  10  fra cert:  0.7400000095367432
Validation on real data: 
LOSS self-supervised train 1.4273014664649963, valid (%cert) 0.7599999904632568
EPOCH : 4 TIME:  2022-02-18 09:27:26.744062
Training on real data with self-supervision: 
Batch  1  loss:  1.510329246520996  pc loss:  0.059956345707178116  kp loss:  0.01142058614641428
Batch  1  fra cert:  0.8399999737739563
Batch  2  loss:  1.6549334526062012  pc loss:  0.06583628803491592  kp loss:  0.009026340208947659
Batch  2  fra cert:  0.7400000095367432
Batch  3  loss:  1.6410045623779297  pc loss:  0.06533811241388321  kp loss:  0.00755184143781662
Batch  3  fra cert:  0.7599999904632568
Batch  4  loss:  1.588819146156311  pc loss:  0.06325839459896088  kp loss:  0.007359318435192108
Batch  4  fra cert:  0.8399999737739563
Batch  5  loss:  1.5007556676864624  pc loss:  0.05972946062684059  kp loss:  0.007519072853028774
Batch  5  fra cert:  0.8199999928474426
Batch  6  loss:  1.4665359258651733  pc loss:  0.05839284881949425  kp loss:  0.006714674178510904
Batch  6  fra cert:  0.8199999928474426
Batch  7  loss:  1.3984006643295288  pc loss:  0.05564596876502037  kp loss:  0.007251465227454901
Batch  7  fra cert:  0.85999995470047
Batch  8  loss:  1.6016960144042969  pc loss:  0.06377414613962173  kp loss:  0.007342387922108173
Batch  8  fra cert:  0.8199999928474426
Batch  9  loss:  1.482664704322815  pc loss:  0.058985382318496704  kp loss:  0.008030126802623272
Batch  9  fra cert:  0.9199999570846558
Batch  10  loss:  1.314650058746338  pc loss:  0.05226001888513565  kp loss:  0.008149566128849983
Batch  10  fra cert:  0.8999999761581421
Validation on real data: 
LOSS self-supervised train 1.5159789443016052, valid (%cert) 0.8799999952316284
EPOCH : 5 TIME:  2022-02-18 09:50:46.703451
Training on real data with self-supervision: 
Batch  1  loss:  1.4970510005950928  pc loss:  0.05946602299809456  kp loss:  0.010400422848761082
Batch  1  fra cert:  0.8199999928474426
Batch  2  loss:  1.7710630893707275  pc loss:  0.07050257176160812  kp loss:  0.00849878042936325
Batch  2  fra cert:  0.8199999928474426
Batch  3  loss:  1.3830682039260864  pc loss:  0.054972659796476364  kp loss:  0.008751798421144485
Batch  3  fra cert:  0.8799999952316284
Batch  4  loss:  1.2094216346740723  pc loss:  0.04799534007906914  kp loss:  0.009538119658827782
Batch  4  fra cert:  0.9199999570846558
Batch  5  loss:  1.4839802980422974  pc loss:  0.05901994928717613  kp loss:  0.00848162081092596
Batch  5  fra cert:  0.9199999570846558
Batch  6  loss:  1.4511011838912964  pc loss:  0.057710666209459305  kp loss:  0.008334540762007236
Batch  6  fra cert:  0.9399999976158142
Batch  7  loss:  1.546012043952942  pc loss:  0.061531439423561096  kp loss:  0.007726113777607679
Batch  7  fra cert:  0.9599999785423279
Batch  8  loss:  1.5167632102966309  pc loss:  0.0603863000869751  kp loss:  0.0071057602763175964
Batch  8  fra cert:  0.8799999952316284
Batch  9  loss:  1.5945391654968262  pc loss:  0.0635206550359726  kp loss:  0.006522719282656908
Batch  9  fra cert:  0.8199999928474426
Batch  10  loss:  1.3495912551879883  pc loss:  0.05366342514753342  kp loss:  0.008005612529814243
Batch  10  fra cert:  0.9399999976158142
Validation on real data: 
LOSS self-supervised train 1.480259108543396, valid (%cert) 0.8199999928474426
EPOCH : 6 TIME:  2022-02-18 10:13:56.933284
Training on real data with self-supervision: 
Batch  1  loss:  1.4609185457229614  pc loss:  0.058100998401641846  kp loss:  0.0083936657756567
Batch  1  fra cert:  0.8999999761581421
Batch  2  loss:  1.4017550945281982  pc loss:  0.05576642230153084  kp loss:  0.007594575639814138
Batch  2  fra cert:  0.8999999761581421
Batch  3  loss:  1.4133771657943726  pc loss:  0.05618807300925255  kp loss:  0.008675341494381428
Batch  3  fra cert:  0.8799999952316284
Batch  4  loss:  1.58997642993927  pc loss:  0.06325079500675201  kp loss:  0.008706562221050262
Batch  4  fra cert:  0.8199999928474426
Batch  5  loss:  1.4411932229995728  pc loss:  0.05724157392978668  kp loss:  0.010153868235647678
Batch  5  fra cert:  0.9199999570846558
Batch  6  loss:  1.2416749000549316  pc loss:  0.04931199923157692  kp loss:  0.008874841034412384
Batch  6  fra cert:  0.9799999594688416
Batch  7  loss:  1.3201576471328735  pc loss:  0.052486732602119446  kp loss:  0.007989231497049332
Batch  7  fra cert:  0.8799999952316284
Batch  8  loss:  1.4431815147399902  pc loss:  0.057416435331106186  kp loss:  0.0077706435695290565
Batch  8  fra cert:  0.85999995470047
Batch  9  loss:  1.436260461807251  pc loss:  0.05710645392537117  kp loss:  0.008599106222391129
Batch  9  fra cert:  0.8999999761581421
Batch  10  loss:  1.4517027139663696  pc loss:  0.05769864097237587  kp loss:  0.009236674755811691
Batch  10  fra cert:  0.8999999761581421
Validation on real data: 
LOSS self-supervised train 1.420019769668579, valid (%cert) 0.85999995470047
EPOCH : 7 TIME:  2022-02-18 10:37:04.893802
Training on real data with self-supervision: 
Batch  1  loss:  1.4320508241653442  pc loss:  0.0569685734808445  kp loss:  0.007836490869522095
Batch  1  fra cert:  0.8999999761581421
Batch  2  loss:  1.5509923696517944  pc loss:  0.06175343692302704  kp loss:  0.0071565257385373116
Batch  2  fra cert:  0.8199999928474426
Batch  3  loss:  1.4194217920303345  pc loss:  0.05650733411312103  kp loss:  0.006738390773534775
Batch  3  fra cert:  0.8999999761581421
Batch  4  loss:  1.3992468118667603  pc loss:  0.055661220103502274  kp loss:  0.007716313004493713
Batch  4  fra cert:  0.9399999976158142
Batch  5  loss:  1.759984016418457  pc loss:  0.070177361369133  kp loss:  0.005549980327486992
Batch  5  fra cert:  0.7999999523162842
Batch  6  loss:  1.4205580949783325  pc loss:  0.05658719688653946  kp loss:  0.0058782463893294334
Batch  6  fra cert:  0.8799999952316284
Batch  7  loss:  1.5601856708526611  pc loss:  0.06216124817728996  kp loss:  0.006154437083750963
Batch  7  fra cert:  0.9199999570846558
Batch  8  loss:  1.497225046157837  pc loss:  0.05967237800359726  kp loss:  0.005415581166744232
Batch  8  fra cert:  0.85999995470047
Batch  9  loss:  1.538401484489441  pc loss:  0.06131885200738907  kp loss:  0.005430186167359352
Batch  9  fra cert:  0.85999995470047
Batch  10  loss:  1.5988435745239258  pc loss:  0.06370694190263748  kp loss:  0.006170009728521109
Batch  10  fra cert:  0.8399999737739563
Validation on real data: 
LOSS self-supervised train 1.5176909685134887, valid (%cert) 0.8999999761581421
EPOCH : 8 TIME:  2022-02-18 10:59:58.256607
Training on real data with self-supervision: 
Batch  1  loss:  1.6184443235397339  pc loss:  0.06449021399021149  kp loss:  0.00618902500718832
Batch  1  fra cert:  0.8199999928474426
Batch  2  loss:  1.3078851699829102  pc loss:  0.05205681547522545  kp loss:  0.006464785896241665
Batch  2  fra cert:  0.9199999570846558
Batch  3  loss:  1.5470325946807861  pc loss:  0.06161242350935936  kp loss:  0.006721958983689547
Batch  3  fra cert:  0.8799999952316284
Batch  4  loss:  1.2619479894638062  pc loss:  0.050225771963596344  kp loss:  0.006303721573203802
Batch  4  fra cert:  0.9199999570846558
Batch  5  loss:  1.5646895170211792  pc loss:  0.062357742339372635  kp loss:  0.005746058188378811
Batch  5  fra cert:  0.85999995470047
Batch  6  loss:  1.4607031345367432  pc loss:  0.05816306173801422  kp loss:  0.0066265519708395
Batch  6  fra cert:  0.8999999761581421
Batch  7  loss:  1.6302944421768188  pc loss:  0.06494356691837311  kp loss:  0.0067053185775876045
Batch  7  fra cert:  0.8199999928474426
Batch  8  loss:  1.4016551971435547  pc loss:  0.055804718285799026  kp loss:  0.006537163630127907
Batch  8  fra cert:  0.8999999761581421
Batch  9  loss:  1.502389907836914  pc loss:  0.059833284467458725  kp loss:  0.006557810120284557
Batch  9  fra cert:  0.8999999761581421
Batch  10  loss:  1.6926134824752808  pc loss:  0.06749334186315536  kp loss:  0.0052799019031226635
Batch  10  fra cert:  0.85999995470047
Validation on real data: 
LOSS self-supervised train 1.4987655758857727, valid (%cert) 0.7999999523162842
EPOCH : 9 TIME:  2022-02-18 11:23:10.809605
Training on real data with self-supervision: 
Batch  1  loss:  1.6402146816253662  pc loss:  0.06537854671478271  kp loss:  0.005750986281782389
Batch  1  fra cert:  0.85999995470047
Batch  2  loss:  1.5428820848464966  pc loss:  0.061455138027668  kp loss:  0.006503557786345482
Batch  2  fra cert:  0.8399999737739563
Batch  3  loss:  1.6410937309265137  pc loss:  0.06539229303598404  kp loss:  0.006286440882831812
Batch  3  fra cert:  0.8999999761581421
Batch  4  loss:  1.4660320281982422  pc loss:  0.05838044360280037  kp loss:  0.006520956754684448
Batch  4  fra cert:  0.85999995470047
Batch  5  loss:  1.4542733430862427  pc loss:  0.05795447155833244  kp loss:  0.005411466117948294
Batch  5  fra cert:  0.8399999737739563
Batch  6  loss:  1.4336442947387695  pc loss:  0.05711488798260689  kp loss:  0.005772145930677652
Batch  6  fra cert:  0.8799999952316284
Batch  7  loss:  1.358383297920227  pc loss:  0.054077837616205215  kp loss:  0.006437269970774651
Batch  7  fra cert:  0.8999999761581421
Batch  8  loss:  1.66080641746521  pc loss:  0.06619144231081009  kp loss:  0.006020262837409973
Batch  8  fra cert:  0.8799999952316284
Batch  9  loss:  1.4556082487106323  pc loss:  0.05800289660692215  kp loss:  0.005535864736884832
Batch  9  fra cert:  0.8999999761581421
Batch  10  loss:  1.3801363706588745  pc loss:  0.054939959198236465  kp loss:  0.0066373529843986034
Batch  10  fra cert:  0.8999999761581421
Validation on real data: 
LOSS self-supervised train 1.5033074498176575, valid (%cert) 0.8799999952316284
EPOCH : 10 TIME:  2022-02-18 11:46:15.014464
Training on real data with self-supervision: 
Batch  1  loss:  1.524539589881897  pc loss:  0.060749828815460205  kp loss:  0.005793983116745949
Batch  1  fra cert:  0.8999999761581421
Batch  2  loss:  1.5131196975708008  pc loss:  0.06031760200858116  kp loss:  0.005179612897336483
Batch  2  fra cert:  0.8999999761581421
Batch  3  loss:  1.3933812379837036  pc loss:  0.05551633983850479  kp loss:  0.005472720600664616
Batch  3  fra cert:  0.8799999952316284
Batch  4  loss:  1.3299020528793335  pc loss:  0.0529845654964447  kp loss:  0.005287941545248032
Batch  4  fra cert:  0.8999999761581421
Batch  5  loss:  1.3635138273239136  pc loss:  0.05430865287780762  kp loss:  0.005797550547868013
Batch  5  fra cert:  0.8999999761581421
Batch  6  loss:  1.6745656728744507  pc loss:  0.06676124036312103  kp loss:  0.005534673575311899
Batch  6  fra cert:  0.8799999952316284
Batch  7  loss:  1.4055933952331543  pc loss:  0.05601015314459801  kp loss:  0.005339621100574732
Batch  7  fra cert:  0.9399999976158142
Batch  8  loss:  1.2913647890090942  pc loss:  0.05142664909362793  kp loss:  0.005698541644960642
Batch  8  fra cert:  0.9199999570846558
Batch  9  loss:  1.4098376035690308  pc loss:  0.056168388575315475  kp loss:  0.005627833306789398
Batch  9  fra cert:  0.9599999785423279
Batch  10  loss:  1.2196532487869263  pc loss:  0.048566266894340515  kp loss:  0.005496572237461805
Batch  10  fra cert:  0.9599999785423279
Validation on real data: 
LOSS self-supervised train 1.4125471115112305, valid (%cert) 0.9399999976158142
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
