python expt_self_supervised_training.py
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Training:  chair ; Model ID: 1cc6f2ed3d684fa245f213b8994b4a04
--------------------
Running self_supervised_training:  2022-02-18 14:53:41.224728
--------------------
device is  cuda
--------------------
Number of trainable parameters:  894622
EPOCH : 1 TIME:  2022-02-18 14:53:43.318195
Training on real data with self-supervision: 
Batch  1  loss:  8.943727493286133  pc loss:  0.3573424816131592  kp loss:  0.01016529742628336
Batch  1  fra cert:  0.09999999403953552
Batch  2  loss:  7.666008472442627  pc loss:  0.3059045076370239  kp loss:  0.01839601807296276
Batch  2  fra cert:  0.17999999225139618
Batch  3  loss:  7.580779075622559  pc loss:  0.30231374502182007  kp loss:  0.022935237735509872
Batch  3  fra cert:  0.2199999988079071
Batch  4  loss:  3.889544725418091  pc loss:  0.15390315651893616  kp loss:  0.04196571186184883
Batch  4  fra cert:  0.4399999976158142
Batch  5  loss:  4.033838272094727  pc loss:  0.1597471982240677  kp loss:  0.0401584729552269
Batch  5  fra cert:  0.47999998927116394
Batch  6  loss:  3.1121668815612793  pc loss:  0.12338186800479889  kp loss:  0.027619995176792145
Batch  6  fra cert:  0.3799999952316284
Batch  7  loss:  1.5568733215332031  pc loss:  0.060425978153944016  kp loss:  0.04622387886047363
Batch  7  fra cert:  0.7199999690055847
Batch  8  loss:  1.7780051231384277  pc loss:  0.06991850584745407  kp loss:  0.030042480677366257
Batch  8  fra cert:  0.6599999666213989
Batch  9  loss:  0.6442152261734009  pc loss:  0.024512121453881264  kp loss:  0.03141219913959503
Batch  9  fra cert:  0.8399999737739563
Batch  10  loss:  0.8755730390548706  pc loss:  0.03415808081626892  kp loss:  0.021620983257889748
Batch  10  fra cert:  0.7599999904632568
Validation on real data: 
LOSS self-supervised train 4.008073163032532, valid (%cert) 0.6599999666213989
EPOCH : 2 TIME:  2022-02-18 15:18:45.471855
Training on real data with self-supervision: 
Batch  1  loss:  0.745000958442688  pc loss:  0.028894877061247826  kp loss:  0.02262905053794384
Batch  1  fra cert:  0.7999999523162842
Batch  2  loss:  0.7757050395011902  pc loss:  0.029850883409380913  kp loss:  0.029432978481054306
Batch  2  fra cert:  0.8199999928474426
Batch  3  loss:  0.7233433723449707  pc loss:  0.027758873999118805  kp loss:  0.0293714739382267
Batch  3  fra cert:  0.8199999928474426
Batch  4  loss:  0.5681676268577576  pc loss:  0.021652227267622948  kp loss:  0.02686193957924843
Batch  4  fra cert:  0.8799999952316284
Batch  5  loss:  0.36491960287094116  pc loss:  0.013715999200940132  kp loss:  0.022019637748599052
Batch  5  fra cert:  0.9399999976158142
Batch  6  loss:  0.24605558812618256  pc loss:  0.00915444828569889  kp loss:  0.01719438098371029
Batch  6  fra cert:  0.9799999594688416
Batch  7  loss:  0.23537765443325043  pc loss:  0.008843693882226944  kp loss:  0.014285311102867126
Batch  7  fra cert:  1.0
Batch  8  loss:  0.19547975063323975  pc loss:  0.007277028635144234  kp loss:  0.013554032891988754
Batch  8  fra cert:  1.0
Batch  9  loss:  0.1931201070547104  pc loss:  0.0071714045479893684  kp loss:  0.013834993354976177
Batch  9  fra cert:  1.0
Batch  10  loss:  0.1958591192960739  pc loss:  0.007276460062712431  kp loss:  0.013947627507150173
Batch  10  fra cert:  1.0
Validation on real data: 
LOSS self-supervised train 0.42430288195610044, valid (%cert) 0.7199999690055847
EPOCH : 3 TIME:  2022-02-18 15:43:38.373718
Training on real data with self-supervision: 
Batch  1  loss:  0.18902787566184998  pc loss:  0.007001893594861031  kp loss:  0.013980532996356487
Batch  1  fra cert:  1.0
Batch  2  loss:  0.19299614429473877  pc loss:  0.007213866803795099  kp loss:  0.012649480253458023
Batch  2  fra cert:  1.0
Batch  3  loss:  0.19180938601493835  pc loss:  0.007265542633831501  kp loss:  0.010170812718570232
Batch  3  fra cert:  1.0
Batch  4  loss:  0.18964222073554993  pc loss:  0.007266349624842405  kp loss:  0.007983479648828506
Batch  4  fra cert:  1.0
Batch  5  loss:  0.1967744380235672  pc loss:  0.007458910811692476  kp loss:  0.010301658883690834
Batch  5  fra cert:  1.0
Batch  6  loss:  0.200272798538208  pc loss:  0.007701698690652847  kp loss:  0.007730341982096434
Batch  6  fra cert:  1.0
Batch  7  loss:  0.19905249774456024  pc loss:  0.007700253743678331  kp loss:  0.006546156480908394
Batch  7  fra cert:  1.0
Batch  8  loss:  0.18848015367984772  pc loss:  0.007249015383422375  kp loss:  0.007254770956933498
Batch  8  fra cert:  1.0
Batch  9  loss:  0.18772247433662415  pc loss:  0.007101716008037329  kp loss:  0.010179577395319939
Batch  9  fra cert:  1.0
Batch  10  loss:  0.18096739053726196  pc loss:  0.007041035685688257  kp loss:  0.004941492807120085
Batch  10  fra cert:  1.0
Validation on real data: 
LOSS self-supervised train 0.19167453795671463, valid (%cert) 1.0
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

